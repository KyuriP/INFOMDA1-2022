---
title: "P1_MartinOkanik"
author: "Martin Okanik"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
params:
  mainfont: Arial
  fontsize: 12pt
  urlcolor: blue
---

# Loading packages

```{r load_packages, message = FALSE, warning = FALSE}

library(ISLR)

library(tidyverse)

library(haven)

library(readxl)

```

# Data types

------------------------------------------------------------------------

1.  **Run the following code in `R` and inspect their data types using the `class()` function. Try to guess beforehand what their types will be!**

------------------------------------------------------------------------

```{r 1}

object_1 <- 1:5

class(object_1) # integer

object_2 <- 1L:5L

class(object_2) # integer

object_3 <- "-123.456"

class(object_3) # character

object_4 <- as.numeric(object_2)

class(object_4) # numeric

object_5 <- letters[object_1]

class(object_5) # character

object_6 <- as.factor(rep(object_5, 2))

class(object_6) # factor

object_7 <- c(1, 2, 3, "4", "5", "6")

class(object_7) # character

```

------------------------------------------------------------------------

2.  **Convert `object_7` back to a vector of numbers using the `as.numeric()` function**

------------------------------------------------------------------------

```{r 2}

object_7 <- as.numeric(object_7)

```

------------------------------------------------------------------------

3.  **Make a list called `objects` containing object 1 to 7 using the `list()` function.**

------------------------------------------------------------------------

```{r 3}

objects <- list(object_1, object_2, object_3, object_4, object_5, object_6,

                object_7)

```

------------------------------------------------------------------------

4.  **Make a data frame out of `object_1`, `object_2`, and `object_5` using the `data.frame()` function**

------------------------------------------------------------------------

```{r 4}

dat <- data.frame(Var1 = object_1, Var2 = object_2, Var3 = object_5)

dat

```

------------------------------------------------------------------------

5.  **Useful functions for determining the size of a data frame are `ncol()` and `nrow()`. Try them out!**

------------------------------------------------------------------------

```{r 5}

ncol(dat)

nrow(dat)

```

# Loading, viewing, and summarising data

------------------------------------------------------------------------

6.  **Use the function `read_csv()` to import the file "data/googleplaystore.csv" and store it in a variable called `apps`.**

------------------------------------------------------------------------

```{r 6}

apps <- read_csv("data/googleplaystore.csv")

apps

```

------------------------------------------------------------------------

7.  **Did any column get a variable type you did not expect?**

------------------------------------------------------------------------

```{r 7}

# (i) Size is <chr> because it is expressed in "M"

# its dimensions would ideally be included in the name, e.g. "Size [M]"

# (ii) Type should perhaps be a factor

# (iii) Price should definitely be numeric

# (iv) Content too

# (v) Generes should be a factor, just like (ii)

# (vi) Last Updated should use some suitable date-time format

```

------------------------------------------------------------------------

8.  **Use the function `head()` to look at the first few rows of the `apps` dataset**

------------------------------------------------------------------------

```{r 8}

head(apps)

```

------------------------------------------------------------------------

9.  **Repeat steps 5, 6, and 7 but now for "data/students.xlsx" (NB: You'll need a function from the package `readxl`). Also try out the function `tail()` and `View()` (with a capital V).**

------------------------------------------------------------------------

```{r 9}

students <- read_xlsx("data/students.xlsx")

head(students)

tail(students)

# student_number should be integer

# programme could be a factor

```

------------------------------------------------------------------------

10. **Create a summary of the three columns in the students dataset using the `summary()` function. What is the range of the grades achieved by the students?**

------------------------------------------------------------------------

```{r 10}

summary(students)

```

# Data transformation with `dplyr` verbs

### Filter

------------------------------------------------------------------------

11. **Look at the help pages for `filter()` (especially the examples) and show the students with a grade lower than 5.5**

------------------------------------------------------------------------

```{r 11}

filter(students, grade < 5.5)

```

------------------------------------------------------------------------

12. **Show only the students with a grade higher than 8 from programme A**

------------------------------------------------------------------------

```{r 12}

filter(students, grade > 8, programme == "A")

```

# Arrange

------------------------------------------------------------------------

13. **Sort the students dataset such that the students from programme A are on top of the data frame and within the programmes the highest grades come first.**

------------------------------------------------------------------------

```{r 13}

arrange(students, programme, -grade)

```

# Select

------------------------------------------------------------------------

14. **Show only the `student_number` and `programme` columns from the students dataset**

------------------------------------------------------------------------

```{r 14}

select(students, student_number, programme)

students <- mutate(students, pass = grade > 5.5)

students

```

------------------------------------------------------------------------

15. **Use `mutate()` and `recode()` to change the codes in the programme column of the students dataset to their names. Store the result in a variable called `students_recoded`**

------------------------------------------------------------------------

```{r 15}

students_recoded <- students %>%

mutate(programme = programme %>% recode("A" = "Science", "B" = "Social Science"))

```

# Data processing pipelines

------------------------------------------------------------------------

16. **Create a data processing pipeline that (a) loads the apps dataset, (b) parses the number of installs as 'Downloads' variable using `mutate` and `parse_number()`, (c) shows only apps with more than 500 000 000 downloads, (d) orders them by rating (best on top), and (e) shows only the relevant columns (you can choose which are relevant, but select at least the `Rating` and `Category` variables). Save the result under the name `popular_apps`.**

------------------------------------------------------------------------

```{r 16}

popular_apps <-

  read_csv("data/googleplaystore.csv") %>%

  mutate(Downloads = parse_number(Installs)) %>%

  filter(Downloads > 5e8) %>%

  arrange(-Rating) %>%

  select(App, Rating, Downloads, Category) %>%

  distinct(App, .keep_all = TRUE)

```

# Grouping and summarisation

------------------------------------------------------------------------

17. **Show the median, minimum, and maximum for the popular apps dataset you made in the previous assignment.**

------------------------------------------------------------------------

```{r 17}

popular_apps %>%

  summarise(

    med = median(Rating),

    min = min(Rating),

    max = max(Rating)

  )

```

------------------------------------------------------------------------

18. **Add the median absolute deviation to the summaries you made before**

------------------------------------------------------------------------

```{r 18}

popular_apps %>%

  summarise(

    med = median(Rating),

    min = min(Rating),

    max = max(Rating),

    mad = mad(Rating)

  )

```

------------------------------------------------------------------------

19. **Create a grouped summary of the ratings per category in the popular apps dataset.**

------------------------------------------------------------------------

```{r 19}

    popular_apps %>%

      group_by(Category) %>%

      summarise(

        med = median(Rating),

        min = min(Rating),

        max = max(Rating),

        mad = mad(Rating)

      )

```

# Final exercise

------------------------------------------------------------------------

20. **Create an interesting summary based on the Google play store apps dataset. An example could be "do games get higher ratings than communication apps?"**

------------------------------------------------------------------------

```{r 20}

# which category has the highest and lowest spread (sd) of rankings?

# what is the entire ranking?

# loading, selecting relevant data, and some preliminary exploration

app_data <- read_csv("data/googleplaystore.csv") %>%

  select(App, Rating, Category) %>%

  na.omit()

str(app_data)

summary(app_data)

# calculating sd of Rating per Category

sd_by_cat <- app_data %>%

  group_by(Category) %>%

  summarise(mean = mean(Rating), sd = sd(Rating), n = n()) %>%

  arrange(sd)

sd_by_cat
```

# CONCLUSION:

according to this dataset, people tend to have:

(i) the most differing opinions about health, bussiness and dating apps

(ii) the least differing opinions about education, weather and entertainment apps

This is in line with the expectation that more important life decisions, which also trigger increased emotions (dating, health etc.) provoke a wider range of reactions, which might also carry over to the relevant apps. Remarkably, weather apps were also spared from people's bad mood, the dataset was probably not collected in Netherlands or the UK...

The mean scores of various categories are different, but the spread of standard deviations is significantly larger than the spread in mean scores. The mean scores for categories with lower deviation seem to be on average very slightly larger compared to those with higher deviation. I cut my analysis before going to any significance tests...
