---
title: "SLV practical 1"
author: "Judith Neve"
date: '2022-09-13'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the packages

```{r}
library(ISLR)
library(tidyverse)
library(haven)
library(readxl)
```

## Data types

### 1. Run the following code in R & inspect their data types using the class() function. Try to guess beforehand what their types will be!

```{r}
object_1 <- 1:5 # numeric
object_2 <- 1L:5L # integer
object_3 <- "-123.456" # character
object_4 <- as.numeric(object_2) # numeric
object_5 <- letters[object_1] # character
object_6 <- as.factor(rep(object_5, 2)) # factor
object_7 <- c(1, 2, 3, "4", "5", "6") # character
```

```{r}
object_1 %>% class() # almost
object_2 %>% class() # correct
object_3 %>% class() # correct
object_4 %>% class() # correct
object_5 %>% class() # correct
object_6 %>% class() # correct
object_7 %>% class() # correct
```

### 2. Convert object_7 back to a vector of numbers using the as.numeric() function

```{r}
object_7_num <- as.numeric(object_7)
```

### 3. Make a list called objects containing object 1 to 7 using the list() function.

```{r}
object_list <- list(object_1, object_2, object_3, object_4, object_5, object_6, object_7) # elements don't have names
```

### 4. Make a dataframe out of objects 1, 2, 5

```{r}
object_df <- data.frame(object_1, object_2, object_5)
```

### 5. Try out ncol() and nrow()

```{r}
ncol(object_df)
nrow(object_df)
```

## Loading, viewing, and summarising data

### 6. Use the function read_csv() to import the file data/googleplaystore.csv and store it in a variable called apps.

```{r}
apps <- read_csv("data/googleplaystore.csv")
```

### 7. Did any column get a variable type you did not expect?

Rating and reviews.

### 8. Use the function head() to look at the first few rows of the apps dataset.

```{r}
head(apps)
```

### 9. Repeat steps 5-7 but now for data/students.xlsx. Also try out the function tail() and View().

```{r}
students <- read_xlsx("data/students.xlsx")

head(students)
tail(students)
View(students)
```

### 10. Create a summary of the three columns in the dataset using the summary() function. What is the range of the grades achieved by the students?

```{r}
summary(students) # range is 4.844-9.291
```

## Data transformation with dplyr verbs

### 11. Show the students with a grade lower than 5.5

```{r}
students %>%
  filter(grade < 5.5)
```

### 12. Show only the students with a grade higher than 8 from programme A

```{r}
students |> # trying out the base pipe operator that I learned about on twitter
  filter(grade > 8 & programme == "A")
```

### 13. Sort the students dataset such that the students from programme A are on top of the dataframe and within the programmes the highest grades come first

```{r}
students |>
  # arrange(programme) |>
  group_by(programme) |>
  arrange(desc(grade), .by_group = TRUE) # this one does both at once
## or I could've used arrange(programme, -grade)
```

### 14. Show only the student_number and programme columns from the students dataset

```{r}
students |>
  select(student_number, programme)
```

### 15. Use mutate and recode to change the codes in the programme column of the students dataset to their names. Store the result in a variable called students_recoded

```{r}
students_recoded <- students |>
  mutate(programme = recode(programme,
                            "A" = "Science",
                            "B" = "Social Science"))
head(students_recoded)
```

## Data processing pipelines

### 16. Create a data processing pipeline that (a) loads the apps dataset, (b) parses the number of installs as ‘Downloads’ variable using mutate and parse_number(), (c) shows only apps with more than 500 000 000 downloads, (d) orders them by rating (best on top), and (e) shows only the relevant columns (you can choose which are relevant, but select at least the Rating and Category variables). Save the result under the name popular_apps.

```{r}
popular_apps <- read_csv("data/googleplaystore.csv") %>%
  mutate(Downloads = parse_number(Installs)) %>%
  filter(Downloads >= 500000000) %>%
  arrange(-Rating) %>%
  select(App, Rating, Category, Downloads) %>%
  distinct(App, .keep_all = TRUE)
head(popular_apps)
```

## Grouping and summarisation

### 17. Show the median, minimum, and maximum for the popular apps dataset you made in the previous assignment

```{r}
popular_apps %>% # assuming it's the rating that we're looking at
  summarise(median = median(Rating),
            min = min(Rating),
            max = max(Rating))
```

### 18. Add the median absolute deviation to the summaries you made before

```{r}
mad <- function(x) {
  median(abs(x - median(x)))
}

popular_apps %>%
  summarise(median = median(Rating),
            mad = mad(Rating),
            min = min(Rating),
            max = max(Rating))
```

### 19. Create a grouped summary of the ratings per category in the popular apps dataset

```{r}
popular_apps %>%
  group_by(Category) %>%
  summarise(n = n(),
            median = median(Rating),
            mad = mad(Rating),
            min = min(Rating),
            max = max(Rating))
```

## Final exercise

### 20. Create an interesting summary based on the Google play store apps dataset. An example could be "do games get higher ratings than communication apps?"

Are apps equally likely to become popular regardless of their category?

```{r}
# we're going to make a histogram where we see the total number of apps in each category and how many of those are popular
ggplot(mapping = aes(y = Category)) +
  geom_bar(data = apps) +
  geom_bar(data = popular_apps, fill = "pink")
```

We really don't see much. Let's only select the categories that have popular apps.

```{r}
ggplot(mapping = aes(y = Category)) +
  geom_bar(data = apps %>% filter(Category %in% popular_apps$Category)) +
  geom_bar(data = popular_apps, fill = "pink")
```

It seems not. Family has the most apps by far but does not even appear; communication has the most popular apps but comparatively does not have that many apps.