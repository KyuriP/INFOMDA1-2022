---
title: "Practical_8"
author: "Hasbini Laura"
date: "31 octobre 2022"
output: html_document
---

# Ensemble methods

## Intrduction

```{r}
library(tidyverse)
library(tidyr)
library(rlang)
library(magrittr)
library(psych)
library(caret)
library(gbm)
library(xgboost)
library(data.table)
library(ggforce)
```

```{r}
set.seed(45)
df <- readRDS("data/train_disease.RDS")
```


#### Question 1 
" Get an impression of the data by looking at the structure of the data and creating some descriptive statistics."

```{r}
head(df)
```

```{r}
tail(df)
```

```{r}
summary(df)
```

```{r}
df %>%
  select(-c(Gender, Disease)) %>%
  describeBy(df$Disease, fast = TRUE)
```

#### Question 2 
"To further explore the data we work with, create some interesting data visualizations that show whether there are interesting patterns in the data."

```{r}
df %>%
  select(-Gender) %>%
  pivot_longer(where(is.numeric)) %>%
  ggplot(aes(x=value, col=Disease, color=Disease)) + 
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~name, scales="free") +
  theme_minimal()
```

```{r}
prop.table(table(df$Gender, df$Disease), margin = 1) %>%
  as.data.frame %>%
  select(Gender = Var1, Disease = Var2, `Relative Frequency` = Freq) %>%
  ggplot(aes(y = `Relative Frequency`, x = Gender, col = Disease, fill = Disease)) +
  geom_histogram(alpha = 0.8, stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Paired") +
  scale_color_brewer(palette = "Paired") +
  theme_minimal()
```


#### Question 3
"Shortly reflect on the difference between bagging, random forests, and boosting."

- **Boosting**
Construct several trees from bootstrap samples, the results from all the trees is then mean. 

- **Random Forest**
Construct several trees from bootstrap samples. Contrary to boosting, here the number of predictors is reduces so that at each step, not all of the predictors can be used. 

- **Boosting**
The tree is builded sequentially and not parralle as the previous techniques. At each step, more weight is given to the misclassified points. 

#### Question 4 
"Apply bagging to the training data, to predict the outcome Disease, using the caret library."

```{r}
cvcontrol <- trainControl(method = "repeatedcv", 
                          number = 10,
                          allowParallel = TRUE)
```

```{r}
bag_train <- train(Disease ~ ., 
                   data = df, 
                   method = 'treebag', 
                   trControl = cvcontrol, 
                   importance=TRUE)
```

#### Question 5 
"Interpret the variable importance measure using the varImp function on the trained model object."

```{r}
bag_train %>%
  varImp %>%
  plot
```


#### Question 6 
"Create training set predictions based on the bagged model, and use the confusionMatrix() function from the caret package to assess itâ€™s performance."

```{r}
confusionMatrix(predict(bag_train, type="raw"), df$Disease)
```

#### Question 7 
"Now ask for the output of the bagged model. Explain why the under both approaches differ."

```{r}
bag_train
```

#### Question 8 
"Fit a random forest to the training data to predict the outcome Disease, using the caret library."

```{r}
rf_train <- train(Disease ~ ., data = df, method='rf', trControl=cvcontrol, importance=TRUE)
```

#### Question 9 
"Again, interpret the variable importance measure using the varImp function on the trained model object. Do you draw the same conclusions as under the bagged model?"

```{r}
rf_train %>%
  varImp %>%
  plot
```
We can see that the most important variables are differents from the ones obtained with the bagging method

#### Question 10
"Output the model output from the random forest. Are we doing better than with the bagged model?"

```{r}
rf_train
```

We can note that the random forest model has a higher accurancy that the bagging method.This means that the random forest performs slightly better for our particular example. 

#### Question 11
" Now, fit a boosting model using the caret library to predict disease status."

```{r}
gbm_train <- train(Disease ~., 
                   data = df,
                   method = 'gbm',
                   verbose = F, 
                   trControl = cvcontrol)
```

#### Question 12 
"Again, interpret the variable importance measure. You will have to call for summary() on the model object you just created. Compare the output to the previously obtained variable importance measures."

```{r}
gbm_train %>%
  varImp %>%
  plot
```

One more time, the most important variables differs from the two previous methods. However we can note that the first most important variable is the same that the one obtained with bagging. 

#### Question 13 
"Output the model output from our gradient boosting procedure. Are we doing better than with the bagged and random forest model?"

```{r}
gbm_train
```

Depending the number of trees, the performances obtained are similar to the one  obtained with random forest. This can be due to our sample or to random variation. 

#### Question 14 
" Download the file shap.R from this Github repository."
```{r}
library(devtools)
source_url("https://github.com/pablo14/shap-values/blob/master/shap.R?raw=TRUE")
```
#### Question 15
"Specify your model as follows, and use it to create predictions on the training data."

```{r}
train_x <- model.matrix(Disease ~., df)[,-1]
train_y <- as.numeric(df$Disease) - 1
xgboost_train <- xgboost(data = train_x, 
                         label = train_y, 
                         max.depth = 10, 
                         eta = 1, 
                         nthread = 4, 
                         nrounds = 4, 
                         objective = "binary:logistic", 
                         verbose = 2)

pred <- tibble(Disease = predict(xgboost_train, newdata=train_x)) %>% mutate(Disease = factor(ifelse(Disease < 0.5, 1, 2), labels = c("Healthy", "Disease")))

table(pred$Disease, df$Disease)
```

#### Question 16
"First, calculate the SHAP rank scores for all variables in the data, and create a variable importance plot using these values. Interpret the plot."

```{r}
shap_results <- shap.score.rank(xgboost_train, X_train = train_x, shap_approx = F)
```
```{r}
var_importance(shap_results)
```

With the boosting method, computed with xgboost, the most important variable is 'Direct_Bilirubin'. The results from the previous plot are highly different from the one obtained with random forest. 

#### Questino 17
"Plot the SHAP values for every individual for every feature and interpret them."

```{r}
shap_long <- shap.prep(shap = shap_results,
                       X_train = train_x)

plot.shap.summary(shap_long)
```

We can see that the variables are differently related to the probability of being diseased. More precisely, a positive Direct_Bilirubin, Alkaline_Phosphotase or a higher age will result in a lower probability of being diseased. 

```{r}
xgb.plot.shap(train_x, features = colnames(train_x), model = xgboost_train, n_col = 3)
```

#### Question 18
"Verify which of the models you created in this practical performs best on the test data."

```{r}
test <- readRDS("data/test_disease.RDS")

bag_test <- predict(bag_train, newdata = test)
rf_test <- predict(rf_train, newdata = test)
gbm_test <- predict(gbm_train, newdata = test)
xbg_test <- predict(xgboost_train, newdata = model.matrix(Disease ~ ., test)[,-1]) %>%
  factor(x = ifelse(. < 0.5, 1, 2), levels = c(1,2), labels = c("Healthy", "Disease"))

list(bag_test, rf_test, gbm_test, xbg_test) %>% map(~ confusionMatrix(.x, test$Disease))
```

Above are the peformances obtained on the test data. We can note that the highest accuracy of $0,77$ is obtained with the gradient boosting methods. The bagging, the random forest and the extreme boosting have respectively an accuracy of $0,72$, $0,76$ and $0,69$. We can also note that the extreme boosting which was performing well on the training set is here the worth one. This can be explained by the fact that this method has a low bias but a high variance.  





