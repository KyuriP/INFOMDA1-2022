---
title: "Practical 4"
author: "Judith Neve"
date: '2022-10-03'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Supervised learning: Regression 1

## Introduction

```{r}
library(ISLR)
library(MASS)
library(tidyverse)
library(magrittr) # for the exposition pipe
```

## Regression in R

### 1. Create a linear model object called lm_ses using the formula medv ~ lstat and the Boston dataset.

```{r}
lm_ses <- Boston %$%
  lm(medv ~ lstat)
```

### 2. Use the function coef() to extract the intercept and slope from the lm_ses object. Interpret the slope coefficient.

```{r}
coef(lm_ses)
# for lstat one point higher, housing value decreases by 0.95 on average
```

### 3. Use summary() to get a summary of the lm_ses object. What do you see? You can use the help file ?summary.lm.

```{r}
summary(lm_ses)
```

### 4. Save the predicted y values to a variable called y_pred

```{r}
y_pred <- predict(lm_ses)
```

### 5. Create a scatter plot with y_pred mapped to the x position and the true y value (Boston$medv) mapped to the y value. What do you see? What would this plot look like if the fit were perfect?

```{r}
ggplot(mapping = aes(x = y_pred, y = Boston$medv)) +
  geom_point()
# some variation
# if the fit were perfect: straight line with intercept 0 and slope 1
```

### 6. Use the seq() function to generate a sequence of 1000 equally spaced values from 0 to 40. Store this vector in a data frame with (data.frame() or tibble()) as its column name lstat. Name the data frame pred_dat.

```{r}
pred_dat <- data.frame(lstat = seq(0, 40, length.out = 1000))
```

### 7. Use the newly created data frame as the newdata argument to a predict() call for lm_ses. Store it in a variable named y_pred_new.

```{r}
y_pred_new <- predict(lm_ses, newdata = pred_dat)
```

## Plotting lm() in ggplot

### 8. Create a scatter plot from the Boston dataset with lstat mapped to the x position and medv mapped to the y position. Store the plot in an object called p_scatter.

```{r}
p_scatter <- Boston %>%
  ggplot(aes(x = lstat, y = medv)) +
  geom_point()

p_scatter
```

### 9. Add the vector y_pred_new to the pred_dat data frame with the name medv.

```{r}
pred_dat$medv <- y_pred_new
```

### 10. Add a geom_line() to p_scatter, with pred_dat as the data argument. What does this line represent?

```{r}
p_scatter +
  geom_line(data = pred_dat)
# the line is the regression line
```

### 11. The interval argument can be used to generate confidence or prediction intervals. Create a new object called y_pred_95 using predict() (again with the pred_dat data) with the interval argument set to “confidence”. What is in this object?

```{r}
y_pred_95 <- predict(lm_ses, interval = "confidence")
# a data frame with fitted value, lower and upper bound of the CI
```

### 12. Create a data frame with 4 columns: medv, lstat, lower, and upper.

```{r}
q12 <- data.frame(medv = Boston$medv,
                  lstat = Boston$lstat,
                  lower = y_pred_95[,"lwr"],
                  upper = y_pred_95[,"upr"])
```

### 13. Add a geom_ribbon() to the plot with the data frame you just made. The ribbon geom requires three aesthetics: x (lstat, already mapped), ymin (lower), and ymax (upper). Add the ribbon below the geom_line() and the geom_points() of before to make sure those remain visible. Give it a nice colour and clean up the plot, too!

```{r}
p_scatter +
  geom_line(data = pred_dat) +
  geom_ribbon(aes(ymin = lower, ymax = upper), data = q12, alpha = 0.5, fill = "pink") +
  theme_minimal()
```

### 14. Explain in your own words what the ribbon represents

It is the 95% confidence interval: we expect the mean of the observations with a given lstat to have a value of medv that would make the point fall within the ribbon.

### 15. Do the same thing, but now with the prediction interval instead of the confidence interval.

```{r}
y_pred_new_95 <- predict(lm_ses, newdata = pred_dat, interval = "prediction")
q15 <- data.frame(medv = pred_dat$medv,
                  lstat = pred_dat$lstat,
                  lower = y_pred_new_95[,"lwr"],
                  upper = y_pred_new_95[,"upr"])

p_scatter +
  geom_line(data = pred_dat) +
  geom_ribbon(aes(ymin = lower, ymax = upper), data = q15, alpha = 0.5, fill = "pink") +
  theme_minimal()
# we now expect 95% of new observations to fall within the ribbon
```

## Mean square error

### 16. Write a function called mse() that takes in two vectors: true y values and predicted y values, and which outputs the mean square error.

```{r}
mse <- function(y_true, y_pred) {
  mean((y_true-y_pred)^2)
}
```

### 17. Make sure your mse() function works correctly by running the following code.

```{r}
mse(1:10, 10:1)
# yes
```

### 18. Calculate the mean square error of the lm_ses model. Use the medv column as y_true and use the predict() method to generate y_pred.

```{r}
mse(Boston$medv, predict(lm_ses))
```

## Train-validation-test split

### 19. The Boston dataset has 506 observations. Use c() and rep() to create a vector with 253 times the word “train”, 152 times the word “validation”, and 101 times the word “test”. Call this vector splits.

```{r}
splits <- c(rep("train", 253),
            rep("validation", 152),
            rep("test", 101))
```

### 20. Use the function sample() to randomly order this vector and add it to the Boston dataset using mutate(). Assign the newly created dataset to a variable called boston_master.

```{r}
boston_master <- Boston %>% 
  mutate(split = sample(splits, length(splits)))
```

### 21. Now use filter() to create a training, validation, and test set from the boston_master data. Call these datasets boston_train, boston_valid, and boston_test.

```{r}
boston_train <- boston_master %>% 
  filter(split == "train")

boston_valid <- boston_master %>% 
  filter(split == "validation")

boston_test <- boston_master %>% 
  filter(split == "test")
```

### 22. Train a linear regression model called model_1 using the training dataset. Use the formula medv ~ lstat like in the first lm() exercise. Use summary() to check that this object is as you expect.

```{r}
model_1 <- boston_train %$%
  lm(medv ~ lstat)

summary(model_1)
```

### 23. Calculate the MSE with this object. Save this value as model_1_mse_train.

```{r}
model_1_mse_train <- mse(boston_train$medv,
                         predict(model_1))
model_1_mse_train
```

### 24. Now calculate the MSE on the validation set and assign it to variable model_1_mse_valid. Hint: use the newdata argument in predict().

```{r}
model_1_mse_valid <- mse(boston_valid$medv,
                         predict(model_1, newdata = data.frame(lstat = boston_valid$lstat)))

model_1_mse_valid
```

### 25. Create a second model model_2 for the train data which includes age and tax as predictors. Calculate the train and validation MSE.

```{r}
model_2 <- boston_train %$%
  lm(medv ~ lstat + age + tax)

model_2_mse_train <- mse(boston_train$medv,
                         predict(model_2))
model_2_mse_train

model_2_mse_valid <- mse(boston_valid$medv,
                         predict(model_2, newdata = data.frame(lstat = boston_valid$lstat,
                                                               age = boston_valid$age,
                                                               tax = boston_valid$tax)))

model_2_mse_valid
```

### 26. Compare model 1 and model 2 in terms of their training and validation MSE. Which would you choose and why?

Training and validation MSE are both lower for model 2, so I would choose model 2.

### 27. Calculate the test MSE for the model of your choice in the previous question. What does this number tell you?

```{r}
model_2_mse_test <- mse(boston_test$medv,
                         predict(model_2, newdata = data.frame(lstat = boston_test$lstat,
                                                               age = boston_test$age,
                                                               tax = boston_test$tax)))

model_2_mse_test
```

## Programming exercise: cross-validation

### 28. Create a function that performs k-fold cross-validation for linear models.

```{r}
kfold <- function(formula, dataset, k, DV) {
  fold <- sample(rep(1:k, ceiling(nrow(dataset)/5)),
                 nrow(dataset))
  folds <- dataset %>% 
    mutate(fold = fold)
  MSE <- c()
  for (i in 1:k) {
    train <- folds %>% 
      filter(fold != i)
    test <- folds %>% 
      filter(fold == i)
    mod <- lm(formula = formula, data = train)
    y <- test[,DV]
    y_pred <- predict(mod, newdata = test)
    MSE <- c(MSE, mse(y, y_pred))
  }
  mean(MSE)
}
```

### 29. Use your function to perform 9-fold cross validation with a linear model with as its formula medv ~ lstat + age + tax. Compare it to a model with as formulat medv ~ lstat + I(lstat^2) + age + tax.

```{r}
kfold(formula(medv ~ lstat + age + tax), Boston, 9, "medv")
```

```{r}
kfold(formula(medv ~ lstat + I(lstat^2) + age + tax), Boston, 9, "medv")
```

