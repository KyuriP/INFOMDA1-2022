---
title: "Timo_van_Veghel_Practical_7"
author: "Timo"
date: "2022-11-06"
output: html_document
---
```{r}
#install.packages("splines")
#install.packages("cowplot")
```

```{r}
library(MASS)
library(splines)
library(ISLR)
library(tidyverse)

set.seed(45)
```

##Question 1:

```{r}
pred_plot <- function(model) {
  x_pred <- seq(min(Boston$lstat), max(Boston$lstat), length.out = 500)
  y_pred <- predict(model, newdata = tibble(lstat = x_pred))
  
  Boston %>% 
    ggplot(aes(x = lstat, y = medv)) +
    geom_point() +
    geom_line(data = tibble(lstat = x_pred, medv = y_pred), size = 1, col = "blue") +
    theme_minimal()
}
```

##Question 2:

```{r}
lin_mod <- lm(medv ~ lstat, data = Boston)
pred_plot(lin_mod)
```

##Question 3:

```{r}
pn3_mod <- lm(medv ~ lstat + I(lstat^2) + I(lstat^3), data = Boston)
pred_plot(pn3_mod)
```

##Question 4:

```{r}
poly(1:5, degree = 3, raw = TRUE)
```

##Question 5:

```{r}
pn3_mod2 <- lm(medv ~ poly(lstat, 3, raw = TRUE), data = Boston)
pred_plot(pn3_mod2)
```

```{r}
summary(pn3_mod2)
```

##Question 6:

```{r}
pw2_mod <- lm(medv ~ I(lstat <= median(lstat)), data = Boston)
pred_plot(pw2_mod)
coef(pw2_mod)
```

##Question 7:

```{r}
pw5_mod <- lm(medv ~ cut(lstat, 5), data = Boston)
pred_plot(pw5_mod)
```

##Question 8:

```{r}
brks <- c(-Inf, quantile(Boston$lstat, probs = c(.2, .4, .6, .8)), Inf)
pwq_mod <- lm(medv ~ cut(lstat, brks), data = Boston)
pred_plot(pwq_mod)
```

##Question 9:

```{r}
piecewise_cubic_basis <- function(vec, knots = 1) {
  # If there is only one section, just return the 3rd order polynomial
  if (knots == 0) return(poly(vec, degree = 3, raw = TRUE))
  
  # cut the vector
  cut_vec <- cut(vec, breaks = knots + 1)
  
  # initialise a matrix for the piecewise polynomial
  out <- matrix(nrow = length(vec), ncol = 0)
  
  # loop over the levels of the cut vector
  for (lvl in levels(cut_vec)) {
    
    # temporary vector
    tmp <- vec
    
    # set all values to 0 except the current section
    tmp[cut_vec != lvl] <- 0
    
    # add the polynomial based on this vector to the matrix
    out <- cbind(out, poly(tmp, degree = 3, raw = TRUE))
    
  }
  
  # return the piecewise polynomial matrix
  out
}
```

##Question 10:

```{r}
pc1_mod <- lm(medv ~ piecewise_cubic_basis(lstat, 1), data = Boston)
pc2_mod <- lm(medv ~ piecewise_cubic_basis(lstat, 2), data = Boston)
pc3_mod <- lm(medv ~ piecewise_cubic_basis(lstat, 3), data = Boston)

pred_plot(pc1_mod)

pred_plot(pc2_mod)

pred_plot(pc3_mod)
```

##Question 11:

```{r}
boston_tpb <- Boston %>% as_tibble %>% select(medv, lstat)
```

##Question 12:

```{r}
boston_tpb <- boston_tpb %>% mutate(lstat2 = lstat^2, lstat3 = lstat^3)
```

##Question 13:

```{r}
boston_tpb <- boston_tpb %>% mutate(lstat_tpb = ifelse(lstat > median(lstat), (lstat - median(lstat))^3, 0))
```

##Question 14:

```{r}
tpb_mod <- lm(medv ~ lstat + lstat2 + lstat3 + lstat_tpb, data = boston_tpb)
summary(tpb_mod)
```

##Question 15:

```{r}
bs1_mod <- lm(medv ~ bs(lstat, knots = median(lstat)), data = Boston)
summary(bs1_mod)

mean(abs(predict(bs1_mod) - predict(tpb_mod)))
```

##Question 16:

```{r}
pred_plot(bs1_mod)
```

##Question 17:

```{r}
ns3_mod <- lm(medv ~ ns(lstat, df = 3), data = Boston)
pred_plot(ns3_mod)
```

##Question 18:

```{r}
library(cowplot)
plot_grid(
  pred_plot(lin_mod) + ggtitle("Linear regression"),
  pred_plot(pn3_mod) + ggtitle("Polynomial"),
  pred_plot(pw5_mod) + ggtitle("Piecewise constant"),
  pred_plot(pc3_mod) + ggtitle("Piecewise cubic"),
  pred_plot(bs1_mod) + ggtitle("Cubic spline"),
  pred_plot(ns3_mod) + ggtitle("Natural spline")
)
```

##Question 19:

```{r}
# first create an mse function
mse <- function(y_true, y_pred) mean((y_true - y_pred)^2)

# add a 12 split column to the boston dataset so we can cross-validate
boston_cv <- Boston %>% mutate(split = sample(rep(1:12, length.out = nrow(Boston))))

# prepare an output matrix with 12 slots per method for mse values
output_matrix <- matrix(nrow = 12, ncol = 6) 
colnames(output_matrix) <- c("lin", "pn3", "pw5", "pc3", "bs1", "ns3")

# loop over the splits, run each method, and return the mse values
for (i in 1:12) {
  train <- boston_cv %>% filter(split != i)
  test  <- boston_cv %>% filter(split == i)
  
  brks <- c(-Inf, 7, 15, 22, Inf)
  
  lin_mod <- lm(medv ~ lstat,                            data = train)
  pn3_mod <- lm(medv ~ poly(lstat, 3),                   data = train)
  pw5_mod <- lm(medv ~ cut(lstat, brks),                 data = train)
  pc3_mod <- lm(medv ~ piecewise_cubic_basis(lstat, 3),  data = train)
  bs1_mod <- lm(medv ~ bs(lstat, knots = median(lstat)), data = train)
  ns3_mod <- lm(medv ~ ns(lstat, df = 3),                data = train)
  
  output_matrix[i, ] <- c(
    mse(test$medv, predict(lin_mod, newdata = test)),
    mse(test$medv, predict(pn3_mod, newdata = test)),
    mse(test$medv, predict(pw5_mod, newdata = test)),
    mse(test$medv, predict(pc3_mod, newdata = test)),
    mse(test$medv, predict(bs1_mod, newdata = test)),
    mse(test$medv, predict(ns3_mod, newdata = test))
  )
}

# this is the comparison of the methods
colMeans(output_matrix)

# we can show it graphically too
tibble(names = as_factor(colnames(output_matrix)), 
       mse   = colMeans(output_matrix)) %>% 
  ggplot(aes(x = names, y = mse, fill = names)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  scale_fill_viridis_d(guide = "none") +
  labs(
    x     = "Method", 
    y     = "Mean squared error", 
    title = "Comparing regression method prediction performance"
  )
```

