---
title: "P7_MartinOkanik"
author: "Martin Okanik"
date: "`r Sys.Date()`"
output: html_document
---

# Supervised learning: Nonlinear Regression

# Introduction

In this practical, we will learn about nonlinear extensions to regression using basis functions and how to create, visualise, and interpret them. Parts of it are adapted from the practicals in ISLR chapter 7.

One of the packages we are going to use is `splines`. For this, you will probably need to `install.packages("splines")` before running the `library()` functions.

```{r}
library(MASS)
library(splines)
library(ISLR)
library(tidyverse)
```

First, we specify a seed as usual.

```{r}
set.seed(45)
```

# Prediction plot

Median housing prices in Boston do not have a linear relation with the proportion of low SES households. Today we are going to focus exclusively on *prediction*.

```{r}
Boston %>% 
  ggplot(aes(x = lstat, y = medv)) +
  geom_point() +
  theme_minimal()
```

First, we need a way of visualising the predictions.

------------------------------------------------------------------------

1.  **Create a function called `pred_plot()` that takes as input an `lm` object, which outputs the above plot but with a prediction line generated from the model object using the `predict()` method.**

------------------------------------------------------------------------

```{r}
pred_plot <- function(model) {
  
  # create a discretized lstat-space on which to plot the prediction curve
  lstat_space = seq(min(Boston$lstat), max(Boston$lstat), length.out = 500)
  
  # generate the corresponding (vertical) medv values for the curve
  medv_pred <- predict(model, newdata = tibble(lstat = lstat_space))

  # finally plot the observed data and the fitted curve
  ggplot() +
  geom_point(data = Boston, aes(x = lstat, y = medv)) +
  geom_line(aes(x = lstat_space, y = medv_pred), colour = "purple") +
  theme_minimal()
}
```

------------------------------------------------------------------------

2.  **Create a linear regression object called `lin_mod` which models `medv` as a function of `lstat`. Check if your prediction plot works by running `pred_plot(lin_mod)`. Do you see anything out of the ordinary with the predictions?**

------------------------------------------------------------------------

```{r}
lin_mod <- lm(medv ~ lstat, data = Boston)
pred_plot(lin_mod)
```

Clearly the linear model is not suitable. It overestimates in the middle and overestimates at the edges.

# Polynomial regression

The first extension to linear regression is polynomial regression, with basis functions bj(xi)=xjibj(xi)=xij ([ISLR, p.Â 270](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf#page=284&zoom=auto,-352,436)).

------------------------------------------------------------------------

3.  **Create another linear model `pn3_mod`, where you add the second and third-degree polynomial terms `I(lstat^2)` and `I(lstat^3)` to the formula. Create a `pred_plot()` with this model.**

------------------------------------------------------------------------

```{r}
pn3_mod <- lm(medv ~ lstat + I(lstat^2) + I(lstat^3), data = Boston)
pred_plot(pn3_mod)
```

The function `poly()` can automatically generate a matrix which contains columns with polynomial basis function outputs.

------------------------------------------------------------------------

4.  **Play around with the poly() function. What output does it generate with the arguments `degree = 3` and `raw = TRUE`?**

------------------------------------------------------------------------

```{r}
poly(1:10, degree = 3, raw = TRUE)
```

with raw = TRUE, it is just the origininal column vector taken to the respective powers. Try raw = FALSE:

```{r}
poly(1:10, degree = 3, raw = FALSE)
```

------------------------------------------------------------------------

5.  **Use the poly() function directly in the model formula to create a 3rd-degree polynomial regression predicting `medv` using `lstat`. Compare the prediction plot to the previous prediction plot you made. What happens if you change the poly() function to `raw = FALSE`?**

------------------------------------------------------------------------

```{r}
pn3_mod_raw <- lm(medv ~ poly(lstat, 3, raw = TRUE), data = Boston)
pred_plot(pn3_mod_raw)
```

It is the same plot as before. Now do the properly orthogonal fit:

```{r}
pn3_mod_ort <- lm(medv ~ poly(lstat, 3, raw = FALSE), data = Boston)
pred_plot(pn3_mod_ort)
```

Even this has not produced visibly different results.

```{r}
summary(pn3_mod)
```

```{r}
summary(pn3_mod_raw)
```

```{r}
summary(pn3_mod_ort)
```

# Piecewise regression

Another basis function we can use is a step function. For example, we can split the `lstat` variable into two groups based on its median and take the average of these groups to predict `medv`.

------------------------------------------------------------------------

6.  **Create a model called `pw2_mod` with one predictor: `I(lstat <= median(lstat))`. Create a pred_plot with this model. Use the coefficients in `coef(pw2_mod)` to find out what the predicted value for a low-lstat neighbourhood is.**

------------------------------------------------------------------------

```{r}
pw2_mod <- lm(medv ~ I(lstat <= median(lstat)), data = Boston)
pred_plot(pw2_mod)
```

```{r}
coef(pw2_mod)
```

------------------------------------------------------------------------

7.  **Use the `cut()` function in the formula to generate a piecewise regression model called `pw5_mod` that contains 5 equally spaced sections. Again, plot the result using `pred_plot`.**

------------------------------------------------------------------------

```{r}
pw5_mod <- lm(medv ~ cut(lstat, 5), data = Boston)
pred_plot(pw5_mod)
```

Note that the sections generated by `cut()` are equally spaced in terms of `lstat`, but they do not have equal amounts of data. In fact, the last section has only 9 data points to work with:

    table(cut(Boston$lstat, 5))

    ## 
    ## (1.69,8.98] (8.98,16.2] (16.2,23.5] (23.5,30.7]   (30.7,38] 
    ##         183         183          94          37           9

------------------------------------------------------------------------

8.  **Optional: Create a piecewise regression model `pwq_mod` where the sections are not equally spaced, but have equal amounts of training data. Hint: use the `quantile()` function.**

------------------------------------------------------------------------

```{r}

```

# Piecewise polynomial regression

Combining piecewise regression with polynomial regression, we can write a function that creates a matrix based on a piecewise cubic basis function:

```{r}
piecewise_cubic_basis <- function(vec, knots = 1) {
  
  # identify the trivial case of no knots - return the basic cubic fit
  if (knots == 0) return(poly(vec, degree = 3, raw = TRUE))
  
  # cut the input vector to the desired (nonzero) number of splits
  cut_vec <- cut(vec, breaks = knots + 1)
  
  # initialize the blank matrix for storing the basis functions
  # start with length(vec) blank rows, then add columns so that we get a matrix
  # of shape (length(vec))-by-(3*(knots+1)), with zeroes everywhere except the
  # diagonal blocks of (length(vec)/(knots+1))-by-(3*(knots+1))
  # blocks of (length(vec)/(knots+1))-by-(3*(knots+1)) give the values of the 
  # vector "vec" that are part of the relevant (i-th) cut_vec (1 <= i <= knots+1)
  # raised to the 1st, 2nd, 3rd power  
  out <- matrix(nrow = length(vec), ncol = 0)
  
  # iterate over the (knots+1) desired sub-regions of vec
  for (lvl in levels(cut_vec)) {
    # create a copy of the data vector, to be modified in each iteration:
    tmp <- vec
    # set all values in the temporary vector outside the current level to zero:
    # this restricts the focus on the currently considered subregion, while 
    # later ensuring that the number of rows of matrix remains length(vector)
    tmp[cut_vec != lvl] <- 0 
    # now column-bind the (1st, 2nd, 3rd) powers of the given subset to the 
    # out matrix - thus add a sub-matrix of shape (length(vec))-by-(3)
    # we already made sure that rows outside of the current sub-region are zeros
    # this ensures the block-diagonality of the matrix
    # after column-binding (knots+1) times, we get a full matrix of shape
    # (length(vec))-by-(3*(knots+1))
    out <- cbind(out, poly(tmp, degree = 3, raw = TRUE))
  }
  
  out
}
```

------------------------------------------------------------------------

9.  **This function does not have comments. Copy - paste the function and add comments to each line. To figure out what each line does, you can first create "fake" `vec` and `knots` variables, for example `vec <- 1:20` and `knots <- 2` and try out the lines separately.**

------------------------------------------------------------------------

Comments now included in the function, exploratory lines below

```{r}
piecewise_cubic_basis(1:20, knots = 2)
```

------------------------------------------------------------------------

10. **Create piecewise cubic models with 1, 2, and 3 knots (`pc1_mod` - `pc3_mod`) using this piecewise cubic basis function. Compare them using the `pred_plot()` function.**

------------------------------------------------------------------------

```{r}
pc1_mod <- lm(medv ~ piecewise_cubic_basis(lstat, knots = 1), data = Boston)
pred_plot(pc1_mod)
```

```{r}
pc2_mod <- lm(medv ~ piecewise_cubic_basis(lstat, knots = 2), data = Boston)
pred_plot(pc2_mod)
```

```{r}
pc3_mod <- lm(medv ~ piecewise_cubic_basis(lstat, knots = 3), data = Boston)
pred_plot(pc3_mod)
```

# Splines

We're now going to take out the discontinuities from the piecewise cubic models by creating splines. First, we will manually create a cubic spline with 1 knot at the median by constructing a truncated power basis as per [ISLR page 273](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf#page=287&zoom=auto,-352,436), equation 7.10.

------------------------------------------------------------------------

11. **Create a data frame called `boston_tpb` with the columns `medv` and `lstat` from the `Boston` dataset.**

------------------------------------------------------------------------

```{r}
boston_tpb <- data.frame(medv = Boston$medv, lstat = Boston$lstat)
```

------------------------------------------------------------------------

12. **Now use `mutate` to add squared and cubed versions of the `lstat` variable to this dataset.**

------------------------------------------------------------------------

```{r}
boston_tpb <- boston_tpb %>% mutate(lstat2 = lstat^2, lstat3 = lstat^3)
```

------------------------------------------------------------------------

13. **Use `mutate` to add a column `lstat_tpb` to this dataset which is 0 below the median and has value `(lstat - median(lstat))^3` above the median. Tip: you may want to use `ifelse()` within your `mutate()` call.**

```{r}
boston_tpb <- boston_tpb %>% mutate(lstat_tpb = ifelse(lstat > median(lstat), 0, (lstat - median(lstat))^3))
```

Now we have created a complete truncated power basis for a cubic spline fit.

------------------------------------------------------------------------

14. **Create a linear model `tpb_mod` using the `lm()` function. How many predictors are in the model? How many degrees of freedom does this model have?**

------------------------------------------------------------------------

```{r}
tpb_mod <- lm(medv ~ lstat + lstat2 + lstat3 + lstat_tpb, data = boston_tpb)

summary(tpb_mod)
```

We have 5 degrees of freedom...

The `bs()` function from the `splines` package does all the work for us that we have done in one function call.

------------------------------------------------------------------------

15. **Create a cubic spline model `bs1_mod` with a knot at the median using the `bs()` function. Compare its predictions to those of the `tpb_mod` using the `predict()` function on both models.**

------------------------------------------------------------------------

```{r}
bs1_mod <- lm(medv ~ bs(lstat, degree = 3, knots = median(lstat)), data = Boston)
```

------------------------------------------------------------------------

16. **Create a prediction plot from the `bs1_mod` object using the `plot_pred()` function.**

------------------------------------------------------------------------

```{r}
pred_plot(bs1_mod)
```

Note that this line fits very well, but at the right end of the plot, the curve slopes up. Theoretically, this is unexpected -- always pay attention to which predictions you are making and whether that behaviour is in line with your expectations.

The last extension we will look at is the natural spline. This works in the same way as the cubic spline, with the additional constraint that the function is required to be linear at the boundaries. The `ns()` function from the `splines` package is for generating the basis representation for a natural spline.

------------------------------------------------------------------------

17. **Create a natural cubic spline model (`ns3_mod`) with 3 degrees of freedom using the `ns()` function. Plot it, and compare it to the `bs1_mod`.**

------------------------------------------------------------------------

```{r}
ns3_mod <- lm(medv ~ ns(lstat, df = 3), data = Boston)
pred_plot(ns3_mod)
```

------------------------------------------------------------------------

18. **Plot `lin_mod`, `pn3_mod`, `pw5_mod`, `pc3_mod`, `bs1_mod`, and `ns3_mod` and give them nice titles by adding `+ ggtitle("My title")` to the plot. You may use the function `plot_grid()` from the package `cowplot` to put your plots in a grid.**

------------------------------------------------------------------------

```{r}
library(cowplot)
plot_grid(
  pred_plot(lin_mod) + ggtitle("Linear regression"),
  pred_plot(pn3_mod) + ggtitle("Polynomial"),
  pred_plot(pw5_mod) + ggtitle("Piecewise constant"),
  pred_plot(pc3_mod) + ggtitle("Piecewise cubic"),
  pred_plot(bs1_mod) + ggtitle("Cubic spline"),
  pred_plot(ns3_mod) + ggtitle("Natural spline")
)
```

# Programming assignment (optional)

------------------------------------------------------------------------

19. **Use 12-fold cross validation to determine which of the 6 methods (`lin`, `pn3`, `pw5`, `pc3`, `bs1`, and `ns3`) has the lowest out-of-sample MSE.**

------------------------------------------------------------------------

# Hand-in
